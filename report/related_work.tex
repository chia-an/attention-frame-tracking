Recently, researches start to develop memory-enhanced dialogue systems.
In addition to creating extra frame tracking component to the dialogue system, some methods focus on incorporating memory into existing components such as slot filling and state tracking. Chen et al. \cite{chen2016end} used RNN to encode contextual sentences, which are further encoded using an attention mechanism to enhance the language understanding tagging sequence. Several pieces of research work on improving state tracking: Lee et al. \cite{lee2016task} work at the semantic level, i.e. representing each turn as the NLU results, while Sharma et al. \cite{sharma2019improving} use the textual content directly. Perez et al. \cite{perez2016dialog} approach this problem differently. They formulate state tracking as a question-answering problem and use MemN2N \cite{weston2014memory} to model the memory.

%state tracking review 15
%-MACHINE LEARNING FOR DIALOG STATE TRACKING - A REVIEW

%*transfer learning
%Goal-Oriented Chatbot Dialog Management Bootstrapping with Transfer Learning

%GLOBAL-TO-LOCAL MEMORY POINTER NETWORKS FOR TASK-ORIENTED DIALOGUE???
